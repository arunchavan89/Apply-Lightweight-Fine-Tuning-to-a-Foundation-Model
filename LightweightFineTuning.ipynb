{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: LoRA\n",
    "* Model: gpt2\n",
    "* Evaluation approach:Transformer trainer \n",
    "* Fine-tuning dataset:sms_spam "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required version of datasets in case you have an older version\n",
    "# You will need to choose \"Kernel > Restart Kernel\" from the menu after executing this cell\n",
    "#!pip install -q \"datasets==2.15.0\"\n",
    "#!pip install transformers\n",
    "#!pip install peft\n",
    "#!pip install datasets\n",
    "#!pip install pandas\n",
    "#!pip install numpy\n",
    "#!pip install scikit-learn\n",
    "#!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset Dataset({\n",
      "    features: ['sms', 'label'],\n",
      "    num_rows: 4459\n",
      "})\n",
      "Testing dataset Dataset({\n",
      "    features: ['sms', 'label'],\n",
      "    num_rows: 1115\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sms': 'Had your mobile 10 mths? Update to the latest Camera/Video phones for FREE. KEEP UR SAME NUMBER, Get extra free mins/texts. Text YES for a call\\n',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the sms_spam dataset\n",
    "# See: https://huggingface.co/datasets/sms_spam\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# The sms_spam dataset only has a train split, so we use the train_test_split method to split it into train and test\n",
    "dataset = load_dataset(\"sms_spam\", split=\"train\").train_test_split(\n",
    "    test_size=0.2, shuffle=True, seed=23\n",
    ")\n",
    "\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "# View the dataset characteristics\n",
    "print(\"Training dataset\", dataset[\"train\"])\n",
    "print(\"Testing dataset\", dataset[\"test\"])\n",
    "\n",
    "# Inspect the first example. Do you think this is spam or not?\n",
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5176b07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f7797085a14778b49a2fd75951049a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1115 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sms', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 4459\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Let's use a lambda function to tokenize all the examples\n",
    "tokenized_dataset = {}\n",
    "for split in splits:\n",
    "    tokenized_dataset[split] = dataset[split].map(\n",
    "        lambda x: tokenizer(x[\"sms\"], truncation=True), batched=True\n",
    "    )\n",
    "\n",
    "# Inspect the available columns in the dataset\n",
    "tokenized_dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e9df5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "foundation_model = AutoModelForSequenceClassification.from_pretrained(\"gpt2\", num_labels=2,\n",
    "    id2label={0: \"not spam\", 1: \"spam\"},\n",
    "    label2id={\"not spam\": 0, \"spam\": 1},\n",
    ")\n",
    "foundation_model.config.pad_token_id = tokenizer.pad_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa794bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2ForSequenceClassification(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (score): Linear(in_features=768, out_features=2, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(foundation_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2627baef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca02945d",
   "metadata": {},
   "source": [
    "## Evaluating gpt2 model without changing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3712d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 01:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.046051</td>\n",
       "      <td>0.991031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=140, training_loss=0.10274728012404272, metrics={'train_runtime': 66.5003, 'train_samples_per_second': 67.052, 'train_steps_per_second': 2.105, 'total_flos': 164527132114944.0, 'train_loss': 0.10274728012404272, 'epoch': 1.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "\n",
    "# The HuggingFace Trainer class handles the training and eval loop for PyTorch for us.\n",
    "# Read more about it here https://huggingface.co/docs/transformers/main_classes/trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results/foundational_model',  # Output directory for model predictions and checkpoints\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=1,\n",
    "    logging_dir='./logs/foundational_model',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "# Initialize the Trainer with compute_metrics\n",
    "trainer = Trainer(\n",
    "    model=foundation_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "658cf97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.04605131968855858, 'eval_accuracy': 0.9910313901345291, 'eval_runtime': 5.2555, 'eval_samples_per_second': 212.16, 'eval_steps_per_second': 6.66, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", evaluation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/peft/tuners/lora.py:475: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 150,528 || all params: 124,590,336 || trainable%: 0.1208183594592762\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, PeftModelForSequenceClassification, TaskType, AutoPeftModelForSequenceClassification\n",
    "\n",
    "# PEFT model configuration\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    r=4,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1\n",
    ")\n",
    "\n",
    "# Load the pre-trained GPT-2 model\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"gpt2\", num_labels=2,\n",
    "    id2label={0: \"not spam\", 1: \"spam\"},\n",
    "    label2id={\"not spam\": 0, \"spam\": 1},\n",
    ")\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "peft_model = PeftModelForSequenceClassification(model, peft_config)\n",
    "\n",
    "# Print\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec7fb35",
   "metadata": {},
   "source": [
    "## PEFT Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a65581a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 00:51, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.983300</td>\n",
       "      <td>0.945679</td>\n",
       "      <td>0.719283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=140, training_loss=0.9740984507969448, metrics={'train_runtime': 51.5809, 'train_samples_per_second': 86.447, 'train_steps_per_second': 2.714, 'total_flos': 164815327936512.0, 'train_loss': 0.9740984507969448, 'epoch': 1.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The HuggingFace Trainer class handles the training and eval loop for PyTorch for us.\n",
    "# Read more about it here https://huggingface.co/docs/transformers/main_classes/trainer\n",
    "\n",
    "peft_training_args = TrainingArguments(\n",
    "    output_dir=\"./results/peft_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs/peft_model',\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=100,\n",
    "    warmup_ratio=0.1,\n",
    ")\n",
    "\n",
    "# Initialize the Trainer with compute_metrics\n",
    "peft_trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=peft_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    ")\n",
    "\n",
    "peft_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2efa847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.9456785917282104, 'eval_accuracy': 0.7192825112107624, 'eval_runtime': 7.0263, 'eval_samples_per_second': 158.689, 'eval_steps_per_second': 2.562, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "evaluation_results_peft = peft_trainer.evaluate()\n",
    "print(\"Evaluation Results:\", evaluation_results_peft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791d9dd2",
   "metadata": {},
   "source": [
    "## Save PEFT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f432f53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model.save_pretrained('model/peft_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, PeftModelForSequenceClassification, TaskType, AutoPeftModelForSequenceClassification\n",
    "\n",
    "inference_model = AutoPeftModelForSequenceClassification.from_pretrained(\n",
    "    \"model/peft_model\",\n",
    "    num_labels=2,\n",
    "    id2label={0: \"not spam\", 1: \"spam\"},\n",
    "    label2id={\"not spam\": 0, \"spam\": 1},\n",
    ")\n",
    "inference_model.config.pad_token_id = inference_model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.9456785917282104, 'eval_accuracy': 0.7192825112107624, 'eval_runtime': 7.0144, 'eval_samples_per_second': 158.958, 'eval_steps_per_second': 2.566}\n"
     ]
    }
   ],
   "source": [
    "peft_training_args = TrainingArguments(\n",
    "    output_dir=\"./results/inference_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs/inference_model',\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=100,\n",
    "    warmup_ratio=0.1,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=inference_model,\n",
    "    args=peft_training_args,\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation_results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc96905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def predict(prompt: str) -> str:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")    \n",
    "    inference_model.to(device)\n",
    "\n",
    "    # Prepare the input text\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = inference_model(**inputs)\n",
    "        logits = outputs.logits        \n",
    "\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=1)    \n",
    "    predicted_class_id = probabilities.argmax().item()    \n",
    "    id2label={0: \"spam\", 1: \"not spam\"}\n",
    "    predicted_label = id2label[predicted_class_id]\n",
    "\n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "866ab28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 'Had your mobile 10 mths? Update to the latest Camera/Video phones for FREE.'\n",
      "Predicted label: spam\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "prompt = \"Had your mobile 10 mths? Update to the latest Camera/Video phones for FREE.\"\n",
    "predicted_label = predict(prompt)\n",
    "print(f\"Prompt: '{prompt}'\\nPredicted label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9a32e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 'I am Arun and want to say thanks'\n",
      "Predicted label: spam\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "prompt = \"I am Arun and want to say thanks\"\n",
    "predicted_label = predict(prompt)\n",
    "print(f\"Prompt: '{prompt}'\\nPredicted label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834deda0",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "## Compare PEFT performance to performance of the original foundational model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9928fe",
   "metadata": {},
   "source": [
    "* It's evident that the GPT-2 model demonstrated superior performance for this particular dataset and task, suggesting that fine-tuning isn't always guaranteed to enhance accuracy.\n",
    "\n",
    "* Exploring the impact of increasing the number of epochs could have provided further insights or potentially led to higher accuracy levels."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
